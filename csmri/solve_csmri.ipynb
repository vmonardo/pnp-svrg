{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Solve the Compressed-Sensing Magnetic Resonance Imaging (CS-MRI) Reconstruction Problem\n",
    "\n",
    "## Problem formulation\n",
    "\n",
    "$\\boldsymbol{y} = \\boldsymbol{M} \\odot (\\boldsymbol{F} \\boldsymbol{X} \\boldsymbol{F} + \\boldsymbol{\\varepsilon}) , \\hspace{2ex} \\boldsymbol{\\varepsilon} \\sim \\mathcal{N} (0, \\sigma^2 \\boldsymbol{I}), \\hspace{2ex} \\sigma \\geq 0.$\n",
    "\n",
    "- $\\boldsymbol{X} \\in \\mathbb{R}^{n \\times n}$: unknown image to recover \n",
    "- $\\boldsymbol{F} \\in \\mathbb{C}^{n \\times n}$: DFT matrix (https://en.wikipedia.org/wiki/DFT_matrix) \n",
    "- $\\boldsymbol{M} \\in \\{0 ,1\\}^{n \\times n}$: 0-1 mask that denotes which Fourier coefficients are observed \n",
    "- $\\boldsymbol{\\varepsilon} \\in \\mathbb{R}^{m}$: noise\n",
    "- $ \\sigma \\in \\mathbb{R}^+$: noise level \n",
    "- $ \\boldsymbol{y} \\in \\mathbb{C}^{m}$: observed measurements (Fourier coefficients) \n",
    "- $ \\odot : \\mathbb{C}^{n_1 \\times n_2} \\times \\mathbb{C}^{n_1 \\times n_2} \\mapsto \\mathbb{C}^{n_1 \\times n_2}$: denotes the Kronecker product (https://en.wikipedia.org/wiki/Kronecker_product)\n",
    "\n",
    "\n",
    "## Loss function, gradients\n",
    "\n",
    "### Loss function:\n",
    "\n",
    "$\\ell ({\\boldsymbol{X}}) = \\frac{1}{2m} \\| \\boldsymbol{M} \\odot (\\boldsymbol{y} - \\boldsymbol{F} \\boldsymbol{X} \\boldsymbol{F}) \\|_2^2$\n",
    "\n",
    "### Loss function as a finite sum:\n",
    "\n",
    "$\\ell (\\boldsymbol{X}) := \\frac{1}{m} \\sum_{\\{ i, j | y_{i, j} \\not= 0 \\}} \\ell_{i,j}(\\boldsymbol{X}) = \\frac{1}{m}\\sum_{\\{ i, j | y_{i, j} \\not= 0 \\}} \\frac{1}{2}(y_i - \\boldsymbol{f}_i^\\top \\boldsymbol{X} \\boldsymbol{f}_j)^2$\n",
    "\n",
    "- $\\boldsymbol{f}_i \\in \\mathbb{C}^m$: the $i^{\\text{th}}$ column of the DFT matrix $\\boldsymbol{F}$.\n",
    "\n",
    "\n",
    "### Full gradient:\n",
    "\n",
    "$\\nabla \\ell ({\\boldsymbol{X}}) = \\frac{1}{m}\\boldsymbol{F}^\\dagger \\boldsymbol{M} \\odot(\\boldsymbol{y} - \\boldsymbol{F} \\boldsymbol{X} \\boldsymbol{F} ) \\boldsymbol{F}^\\dagger$\n",
    "\n",
    "### Stochastic gradient:\n",
    "\n",
    "$\\nabla \\ell_{i,j}({\\boldsymbol{X}}) = (y_i - \\boldsymbol{f}_j^\\dagger \\boldsymbol{X}^\\dagger \\boldsymbol{f}_i^\\ast) \\boldsymbol{f}_j^\\dagger\\boldsymbol{f}^\\ast $\n",
    "\n",
    "- $\\dagger : \\mathbb{C}^{n_1 \\times n_2} \\mapsto \\mathbb{C}^{n_2 \\times n_1} $: Hermitian transpose\n",
    "- $\\ast : \\mathbb{C}^{n_1 \\times n_2} \\mapsto \\mathbb{C}^{n_1 \\times n_2} $: Complex conjugate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.full.csmri_gradients import full_grad, stoch_grad, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import dirname, abspath\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "## Set paths\n",
    "data_path=\"../data/Set12/\"\n",
    "save_path=\"./figures/\"\n",
    "image_list = sorted(os.listdir(data_path))\n",
    "\n",
    "## Read test image\n",
    "# normalize image pixels in range [0,1]\n",
    "# orig = np.array(Image.open(data_path + image_list[8])) / 225.0\n",
    "ORIG = Image.open(data_path + image_list[12]).resize((256,256))\n",
    "ORIG = np.array(ORIG) / 255.0\n",
    "mintmp = np.min(ORIG)\n",
    "maxtmp = np.max(ORIG)\n",
    "ORIG = (ORIG - mintmp) / (maxtmp - mintmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display original image\n",
    "orig_fig = plt.figure()\n",
    "ax = orig_fig.add_subplot(1, 1, 1)\n",
    "orig_plot = plt.imshow(orig, cmap='gray', vmin=0, vmax=1)\n",
    "ax.set_title('Original Image')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG## Set signal model parameters\n",
    "prob = .5 \t\t\t\t\t\t\t# percentage of Fourier coefficients measured\n",
    "H, W = ORIG.shape[:2] \t\t\t\t# height and width of orig image\n",
    "N = H*W \t\t\t\t\t\t\t# image dimension\n",
    "sigma = 1\t\t\t\t\t\t\t# noise level of measurements\n",
    "\n",
    "## Make measurements\n",
    "mask = np.random.choice([0, 1], size=(H,W), p=[1 - prob, prob])\t# generate random mask\n",
    "index = np.nonzero(mask)\n",
    "index = np.transpose(index)\n",
    "\n",
    "noises = np.random.normal(0, sigma, (H,W))\t\t\t\t\t\t# generate random noise\n",
    "forig = np.fft.fft2(ORIG)\t\t\t\t\t\t\t\t\t\t# fft2 of image\n",
    "y0 = np.multiply(forig, mask)\t\t\t\t\t\t\t\t\t# noiseless measurements\n",
    "y = y0 + noises \t\t\t\t\t\t\t\t\t\t\t\t# noisy measurements\n",
    "\n",
    "## Initialize variables\n",
    "x_init = np.absolute(np.fft.ifft2(y))\n",
    "mintmp = np.min(x_init)\n",
    "maxtmp = np.max(x_init)\n",
    "x_init = (x_init - mintmp) / (maxtmp - mintmp)\n",
    "x = np.copy(x_init)\n",
    "\n",
    "L = N # lipschitz parameter for 2d dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display inverse 2D-DFT of observed Fourier coefficients\n",
    "init_fig = plt.figure()\n",
    "ax = init_fig.add_subplot(1, 1, 1)\n",
    "init_plot = plt.imshow(x_init, cmap='gray', vmin=0, vmax=1)\n",
    "ax.set_title(f'Initialization, PSNR = {peak_signal_noise_ratio(x_init, ORIG):0.2f}')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "\t\\textbf{PnP-SVRG}(\\boldsymbol{x}_0, \\eta, T_1, T_2): \\\\\n",
    "\t\\text{for } s = 1, 2, . . ., T_1 \\text{ do} \\\\\n",
    "\t\\hspace{2ex} \\tilde{\\boldsymbol{x}} = \\boldsymbol{x}_{s-1} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{w} = \\underbrace{\\nabla d(\\tilde{\\boldsymbol{x}})}_{\\text{full gradient}} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{x}_0 = \\tilde{\\boldsymbol{x}} \\\\\n",
    "\t\\hspace{2ex} \\text{for } t = 1, 2, . . ., T_2 \\text{ do} \\\\\n",
    "\t\\hspace{4ex} \\text{pick } i_t \\in \\{ 1, ..., m \\} \\text{ randomly} \\\\\n",
    "\t\\hspace{4ex} \\boldsymbol{v}_t = \\underbrace{\\nabla d_{i_t} (\\boldsymbol{x}_{t-1}) - \\nabla d_{i_t} (\\tilde{\\boldsymbol{x}}) + \\boldsymbol{w}}_{\\text{stochastic variance-reduced gradient}} \\\\\n",
    "\t\\hspace{4ex} \\boldsymbol{x}_t = \\text{denoise}_\\sigma (\\boldsymbol{x}_{t-1} - \\eta \\boldsymbol{v}_t) \\\\\n",
    "\t\\hspace{2ex} \\text{end} \\\\\n",
    "\t\\hspace{2ex} \\text{set } \\boldsymbol{x}_s = \\boldsymbol{x}_{T_2} \\\\\n",
    "\t\\text{end} \\\\\n",
    "    \\textbf{Output } \\boldsymbol{x}_{T_1}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PnP_SVRG_CSMRI(z, MASK, meas, eta, T1, T2, batch_size, FILTER, patch, orig):\n",
    "    ## See pseudocode above\n",
    "    \n",
    "    ## Obtain info from inputs\n",
    "    H, W = z.shape[:2] # image dimensions\n",
    "    index = np.transpose(np.nonzero(MASK)) # nonzero indices of the mask\n",
    "    \n",
    "    ## Initialize time-keeping variables\n",
    "    time_per_iter = []\n",
    "    psnr_per_iter = []\n",
    "    t0 = 0\n",
    "\n",
    "    ## Main PnP SVRG routine\n",
    "    for i in range(T1):\n",
    "        # outer loop\n",
    "        mu = full_grad(z, MASK, meas)   \t# Gradient at reference point\n",
    "        w = np.copy(z) \t\t\t\t\t# Initialize reference point\n",
    "        start_iter = time.time()\n",
    "        for j in range(T2):\n",
    "            ## inner loop\n",
    "            ind = get_batch(batch_size, H, W, index) \t# Get batch index(indices) in terms of (row, col)\n",
    "\n",
    "            ## calculate stochastic variance-reduced gradient\n",
    "            v = stoch_grad(z, ind, meas) / batch_size - stoch_grad(w, ind, meas) / batch_size + mu\n",
    "            ## take gradient step\n",
    "            z_grad = z - eta*v\n",
    "\n",
    "            ## Denoising\n",
    "            ztilde = np.copy(z_grad)\n",
    "            z = denoise_nl_means(np.real(ztilde), h=FILTER, fast_mode=True, **patch)\n",
    "            \n",
    "            ## Display PSNR at each iteration\n",
    "            print(str(i) + \" \" + str(j) + \" \" + str(peak_signal_noise_ratio(orig, z)))\n",
    "\n",
    "        ## Calculate time and PSNR difference per outer loop\n",
    "        stop_iter = time.time()\n",
    "        time_per_iter.append(stop_iter - start_iter)\n",
    "        psnr_per_iter.append(peak_signal_noise_ratio(ORIG, z))\n",
    "\n",
    "        t0 += 1\n",
    "    ## Output final iterate, time keeping\n",
    "    return z, time_per_iter, psnr_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Run PnP-SVRG\n",
    "T_outer = 50 \t\t\t\t# Number of outer loop iterations\n",
    "T_inner = 20 \t\t\t\t# Number of inner loop iterations\n",
    "eta_SVRG = .05 \t\t\t\t# step size for SVRG\n",
    "batch_size_SVRG=100\n",
    "NLM_filter = .015\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6,  # 13x13 search area\n",
    "                multichannel=True)\n",
    "\n",
    "output_SVRG, time_per_iter_SVRG, psnr_per_iter_SVRG = PnP_SVRG_CSMRI(x_init, mask, y, eta_SVRG, \\\n",
    "                                                                     T_outer, T_inner, batch_size_SVRG, \\\n",
    "                                                                     NLM_filter, patch_kw, ORIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run PnP-SVRG\n",
    "T_outer = 50 \t\t\t\t# Number of outer loop iterations\n",
    "T_inner = 20 \t\t\t\t# Number of inner loop iterations\n",
    "num_trials = 4\n",
    "eta_SVRG_array = np.linspace(.094, .096, num_trials)\n",
    "batch_size_SVRG=10\n",
    "NLM_filter = .015\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6,  # 13x13 search area\n",
    "                multichannel=True)\n",
    "\n",
    "psnr_per_trial = []\n",
    "for i in range(num_trials):\n",
    "    output_SVRG, time_per_iter_SVRG, psnr_per_iter_SVRG = PnP_SVRG_CSMRI(x_init, mask, y, eta_SVRG_array[i], \\\n",
    "                                                                     T_outer, T_inner, batch_size_SVRG, \\\n",
    "                                                                     NLM_filter, patch_kw, ORIG)\n",
    "    psnr_per_trial.append(psnr_per_iter_SVRG[-1])\n",
    "\n",
    "# # Figure to display iteration count/ clock time vs PSNR for all algorithms\n",
    "# psnr_fig, psnr_ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
    "\n",
    "# psnr_ax[0].plot(eta_SVRG_array, psnr_per_trial)\n",
    "\n",
    "# psnr_fig.tight_layout()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "svrg_fig = plt.figure()\n",
    "ax = svrg_fig.add_subplot(1, 1, 1)\n",
    "svrg_plot = plt.plot(eta_SVRG_array, psnr_per_trial)\n",
    "ax.set_title(f\"Finding Step Size\")\n",
    "ax.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run PnP-SVRG\n",
    "T_outer = 50 \t\t\t\t# Number of outer loop iterations\n",
    "T_inner = 20 \t\t\t\t# Number of inner loop iterations\n",
    "num_trials = 4\n",
    "eta_SVRG = .095\n",
    "batch_size_SVRG=np.linspace(10, 1000, 10)\n",
    "NLM_filter = .015\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6,  # 13x13 search area\n",
    "                multichannel=True)\n",
    "\n",
    "psnr_per_trial = []\n",
    "for i in range(num_trials):\n",
    "    output_SVRG, time_per_iter_SVRG, psnr_per_iter_SVRG = PnP_SVRG_CSMRI(x_init, mask, y, eta_SVRG, \\\n",
    "                                                                     T_outer, T_inner, batch_size_SVRG[i], \\\n",
    "                                                                     NLM_filter, patch_kw, ORIG)\n",
    "    psnr_per_trial.append(psnr_per_iter_SVRG[-1])\n",
    "\n",
    "# # Figure to display iteration count/ clock time vs PSNR for all algorithms\n",
    "# psnr_fig, psnr_ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
    "\n",
    "# psnr_ax[0].plot(eta_SVRG_array, psnr_per_trial)\n",
    "\n",
    "# psnr_fig.tight_layout()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "svrg_fig = plt.figure()\n",
    "ax = svrg_fig.add_subplot(1, 1, 1)\n",
    "svrg_plot = plt.plot(eta_SVRG_array, psnr_per_trial)\n",
    "ax.set_title(f\"Finding Batch Size\")\n",
    "ax.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display output of PnP-SVRG algorithm\n",
    "psnr_output_SVRG = peak_signal_noise_ratio(ORIG, output_SVRG)\n",
    "svrg_fig = plt.figure()\n",
    "ax = svrg_fig.add_subplot(1, 1, 1)\n",
    "svrg_plot = plt.imshow(output_SVRG, cmap='gray', vmin=0, vmax=1)\n",
    "ax.set_title(f\"PnP-SVRG (Ours), PSNR = {psnr_output_SVRG:0.2f}\")\n",
    "ax.axis('off')\n",
    "\n",
    "# Figure to display iteration count/ clock time vs PSNR for all algorithms\n",
    "psnr_fig, psnr_ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\n",
    "\n",
    "psnr_ax[0].plot(np.cumsum(time_per_iter_SVRG), psnr_per_iter_SVRG)\n",
    "\n",
    "psnr_ax[1].plot(range(np.cumsum(time_per_iter_SVRG).size), psnr_per_iter_SVRG)\n",
    "\n",
    "psnr_ax[0].set(xlabel='time (s)', ylabel='PSNR (dB)')\n",
    "psnr_ax[0].legend(('PnP-SVRG'), loc='lower right')\n",
    "psnr_ax[0].grid()\n",
    "\n",
    "psnr_ax[1].set(xlabel='iteration', ylabel='PSNR (dB)')\n",
    "psnr_ax[1].legend(\"PnP-SVRG\", loc='lower right')\n",
    "psnr_ax[1].grid()\n",
    "\n",
    "psnr_fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "    \\textbf{PnP-GD}(\\boldsymbol{x}_0, \\eta, T): \\\\\n",
    "    \\text{for } t = 1, 2, . . ., T \\text{ do} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{x}_t = \\boldsymbol{x}_{t-1} - \\eta \\nabla \\ell (\\boldsymbol{x}_{t-1}) \\\\\n",
    "    \\hspace{2ex} \\boldsymbol{x}_t = \\text{denoise}_\\sigma (\\boldsymbol{x}_t) \\\\\n",
    "    \\text{end} \\\\\n",
    "    \\textbf{Output } \\boldsymbol{x}_T\n",
    "\\end{equation}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PnP_GD_CSMRI(z, MASK, meas, eta, T, FILTER, patch, orig):\n",
    "    ## Obtain info from inputs\n",
    "    H, W = z.shape[:2] # image dimensions\n",
    "    index = np.transpose(np.nonzero(MASK)) # nonzero indices of the mask\n",
    "    \n",
    "    ## Initialize time-keeping variables\n",
    "    time_per_iter = []\n",
    "    psnr_per_iter = []\n",
    "    t1 = 0\n",
    "    \n",
    "    # Main PnP GD routine\n",
    "    for i in range(T_GD):\n",
    "        start_iter = time.time()\n",
    "        \n",
    "        ## Gradient Update\n",
    "        v = full_grad(z, mask, y)\n",
    "        z = z - eta * v\n",
    "\n",
    "        # Denoising\n",
    "        ztilde = np.copy(z)\n",
    "        z = denoise_nl_means(np.real(ztilde), h=FILTER, fast_mode=True, **patch)\n",
    "    \n",
    "        ## Log timing\n",
    "        stop_iter = time.time()\n",
    "        time_per_iter.append(stop_iter-start_iter)\n",
    "        psnr_per_iter.append(peak_signal_noise_ratio(orig, z))\n",
    "\n",
    "        ## Display PSNR at each iteration\n",
    "        print(str(i) + \" \" + str(peak_signal_noise_ratio(orig, z)))\n",
    "        t1 += 1\n",
    "    return z, time_per_iter, psnr_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_GD = 1000\n",
    "eta_GD = .8\n",
    "NLM_filter = .015\t\t\t \t\t \n",
    "\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6,  # 13x13 search area\n",
    "                multichannel=True)\n",
    "\n",
    "output_GD, time_per_iter_GD, psnr_per_iter_GD = PnP_GD_CSMRI(x_init, mask, y, eta_GD, T_GD, NLM_filter, patch_kw, ORIG)\n",
    "\n",
    "# Figure to display iteration count/ clock time vs PSNR for all algorithms\n",
    "psnr_fig, psnr_ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\n",
    "\n",
    "psnr_ax[0].plot(np.cumsum(time_per_iter_SVRG), psnr_per_iter_SVRG)\n",
    "\n",
    "psnr_ax[1].plot(range(np.cumsum(time_per_iter_SVRG).size), psnr_per_iter_SVRG)\n",
    "\n",
    "psnr_ax[0].set(xlabel='time (s)', ylabel='PSNR (dB)')\n",
    "psnr_ax[0].legend(('PnP-SVRG'), loc='lower right')\n",
    "psnr_ax[0].grid()\n",
    "\n",
    "psnr_ax[1].set(xlabel='iteration', ylabel='PSNR (dB)')\n",
    "psnr_ax[1].legend(\"PnP-SVRG\", loc='lower right')\n",
    "psnr_ax[1].grid()\n",
    "\n",
    "psnr_fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display output of PnP-GD\n",
    "psnr_output_GD = peak_signal_noise_ratio(ORIG, output_GD)\n",
    "gd_fig = plt.figure()\n",
    "ax = gd_fig.add_subplot(1, 1, 1)\n",
    "gd_plot = plt.imshow(output_GD, cmap='gray', vmin=0, vmax=1)\n",
    "ax.set_title(f\"PnP-GD, PSNR = {psnr_output_GD:0.2f}\")\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "    \\textbf{PnP-SGD}(\\boldsymbol{x}_0, \\eta, T): \\\\\n",
    "    \\text{for } t = 1, 2, . . ., T \\text{ do} \\\\\n",
    "    \\hspace{2ex} \\text{pick } i_t \\in \\{ 1, ..., m \\} \\text{ randomly} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{x}_t = \\boldsymbol{x}_{k-1} - \\eta \\nabla \\ell_{i_t} (\\boldsymbol{x}_{t-1}) \\\\\n",
    "    \\hspace{2ex} \\boldsymbol{x}_t = \\text{denoise}_\\sigma (\\boldsymbol{x}_t) \\\\\n",
    "    \\text{end} \\\\\n",
    "    \\textbf{Output } \\boldsymbol{x}_T\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PnP_SGD_CSMRI(z, MASK, meas, eta, T, batch_size, FILTER, patch, orig):\n",
    "    ## Obtain info from inputs\n",
    "    H, W = z.shape[:2] # image dimensions\n",
    "    index = np.transpose(np.nonzero(MASK)) # nonzero indices of the mask\n",
    "    \n",
    "    ## Initialize time-keeping variables\n",
    "    time_per_iter = []\n",
    "    psnr_per_iter = []\n",
    "    t2 = 0\n",
    "    \n",
    "    # Main PnP SGD routine\n",
    "    for i in range(T):\n",
    "        start_iter = time.time()\n",
    "        # Update variables\n",
    "        ind = get_batch(batch_size, H, W, index)\n",
    "        v = stoch_grad(z, MASK, meas, ind)\n",
    "        z = z - eta * v\n",
    "\n",
    "        # Denoising\n",
    "        ztilde = np.copy(z)\n",
    "        z = denoise_nl_means(np.real(ztilde), h=FILTER, fast_mode=True, **patch)\n",
    "        stop_iter = time.time()\n",
    "        time_per_iter.append(stop_iter-start_iter)\n",
    "        psnr_per_iter.append(peak_signal_noise_ratio(orig, z))\n",
    "\n",
    "        print(str(i) + \" \" + str(peak_signal_noise_ratio(orig, z)))\n",
    "        t2 += 1\n",
    "    return z, time_per_iter, psnr_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_SGD = 1000\n",
    "eta_SGD = 1 / L\t\t\t\t# step size for GD\n",
    "batch_size_SGD = 1000\n",
    "NLM_filter = .015\t\t\t \t\t \n",
    "\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6,  # 13x13 search area\n",
    "                multichannel=True)\n",
    "\n",
    "output_SGD, time_per_iter_SGD, psnr_per_iter_SGD = PnP_SGD_CSMRI(x_init, mask, y, eta_SGD, T_SGD, batch_size_SGD, \\\n",
    "                                                                 NLM_filter, patch_kw, ORIG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display output of PnP-SGD\n",
    "psnr_output_SGD = peak_signal_noise_ratio(ORIG, output_SGD)\n",
    "sgd_fig = plt.figure()\n",
    "ax = sgd_fig.add_subplot(1, 1, 1)\n",
    "sgd_plot = plt.imshow(output_SGD, cmap='gray', vmin=0, vmax=1)\n",
    "ax.set_title(f\"PnP-SGD, PSNR = {psnr_output_SGD:0.2f}\")\n",
    "ax.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Need to rewrite code. originally taken from: https://github.com/uclaopt/Provable_Plug_and_Play and not working)\n",
    "\n",
    "$\\begin{equation}\n",
    "    \\textbf{PnP-ADMM}(\\boldsymbol{x}_0, \\boldsymbol{v}_0, \\boldsymbol{u}_0, \\eta, T): \\\\\n",
    "    \\text{for } t = 1, 2, . . ., T \\text{ do} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{x}_t = \\text{prox}_d (\\boldsymbol{v}_{t-1} - \\boldsymbol{u}_{t-1}; \\eta) \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{v}_t = \\text{denoise}_\\sigma (\\boldsymbol{x}_{t} + \\boldsymbol{u}_{t-1}) \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{u}_{t} = \\boldsymbol{u}_{t-1} + (\\boldsymbol{x}_{t} - \\boldsymbol{v}_t) \\\\\n",
    "    \\text{end}\n",
    "\\end{equation}$\n",
    "\n",
    "$\\text{prox}_g (\\boldsymbol{z}; \\eta) \\overset{\\Delta}{=} {\\arg\\min}_{\\boldsymbol{x}} \\left\\{ g(\\boldsymbol{x}) + \\frac{1}{2 \\eta} \\| \\boldsymbol{x} - \\boldsymbol{z} \\|_2^2 \\right\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2.0\n",
    "T_ADMM = 20\n",
    "NLM_filter = .015\t\t\t \t\t \n",
    "\n",
    "x = np.copy(x_init)\n",
    "print(\"Initial PSNR = \" + str(peak_signal_noise_ratio(orig, x)))\n",
    "t3 = 0\n",
    "\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6,  # 13x13 search area\n",
    "                multichannel=True)\n",
    "\n",
    "time_per_iter_ADMM = []\n",
    "psnr_per_iter_ADMM = []\n",
    "\n",
    "v = np.copy(x)\n",
    "u = np.zeros((H,W), dtype=np.float64)\n",
    "\n",
    "\"\"\" Main loop. \"\"\"\n",
    "for i in range(T_ADMM):\n",
    "    start_iter = time.time()\n",
    "    xold = np.copy(x)\n",
    "    vold = np.copy(v)\n",
    "    uold = np.copy(u)\n",
    "    \"\"\" Update variables. \"\"\"\n",
    "\n",
    "    vtilde = np.copy(x+u)\n",
    "    vf = np.fft.fft2(vtilde)\n",
    "    La2 = 1.0/2.0/alpha\n",
    "    vf[index] = (La2 * vf[index] + y[index]) / (1.0 + La2)\n",
    "    v = np.real(np.fft.ifft2(vf))\n",
    "\n",
    "    \"\"\" Denoising step. \"\"\"\n",
    "\n",
    "    xtilde = np.copy(2*v - xold - uold)\n",
    "    mintmp = np.min(xtilde)\n",
    "    maxtmp = np.max(xtilde)\n",
    "    xtilde = (xtilde - mintmp) / (maxtmp - mintmp)\n",
    "\n",
    "    # the reason for the following scaling:\n",
    "    # our denoisers are trained with \"normalized images + noise\"\n",
    "    # so the scale should be 1 + O(sigma)\n",
    "    scale_range = 1.0 + sigma/255.0/2.0 \n",
    "    scale_shift = (1 - scale_range) / 2.0\n",
    "    xtilde = xtilde * scale_range + scale_shift\n",
    "\n",
    "\n",
    "    # pytorch denoising model\n",
    "    x = denoise_nl_means(np.real(xtilde), h=NLM_filter, fast_mode=True, **patch_kw)\n",
    "\n",
    "    # scale and shift the denoised image back\n",
    "    x = (x - scale_shift) / scale_range\n",
    "    x = x * (maxtmp - mintmp) + mintmp\n",
    "\n",
    "    \"\"\" Update variables. \"\"\"\n",
    "    u = uold + xold - v\n",
    "    stop_iter = time.time()\n",
    "\n",
    "    time_per_iter_ADMM.append(stop_iter-start_iter)\n",
    "    psnr_per_iter_ADMM.append(peak_signal_noise_ratio(orig, x))\n",
    "    print(str(i) + \" \" + str(peak_signal_noise_ratio(orig, x)))\n",
    "    t3 += 1\n",
    "\n",
    "output_ADMM = np.copy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display output of PnP-ADMM\n",
    "psnr_output_ADMM = peak_signal_noise_ratio(ORIG, output_ADMM)\n",
    "admm_fig = plt.figure()\n",
    "ax = admm_fig.add_subplot(1, 1, 1)\n",
    "admm_plot = plt.imshow(output_ADMM, cmap='gray', vmin=0, vmax=1)\n",
    "ax.set_title(f\"PnP-ADMM, PSNR = {psnr_output_ADMM:0.2f}\")\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "\t\\textbf{PnP-LSVRG}(\\boldsymbol{x}_0, \\eta, T, p): \\\\\n",
    "    \\text{Initialize } \\boldsymbol{\\tilde{x}} \\\\\n",
    "\t\\text{for } t = 1, 2, . . ., T \\text{ do} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{w} = \\underbrace{\\nabla d(\\tilde{\\boldsymbol{x}})}_{\\text{full gradient}} \\\\\n",
    "    \\hspace{2ex} \\text{pick } i_t \\in \\{ 1, ..., n \\} \\text{ randomly} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{v}_t = \\underbrace{\\nabla d_{i_t} (\\boldsymbol{x}_{t-1}) - \\nabla d_{i_t} (\\tilde{\\boldsymbol{x}}) + \\boldsymbol{w}}_{\\text{stochastic variance-reduced gradient}} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{x}_t = \\text{denoise}_\\sigma (\\boldsymbol{x}_{t-1} - \\eta \\boldsymbol{v}_t) \\\\\n",
    "\t\\hspace{2ex} \\text{Update} \\hspace{1ex} \\tilde{\\boldsymbol{x}} = \\boldsymbol{x}_t \n",
    "\\hspace{2ex} \\text{ w.p. } p \\\\ \\text{end} \\\\\n",
    "    \\textbf{Output } \\boldsymbol{x}_T\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PnP_LSVRG_CSMRI(z, MASK, meas, eta, T, batch_size, p, FILTER, patch, orig):\n",
    "    ## Obtain info from inputs\n",
    "    H, W = z.shape[:2] # image dimensions\n",
    "    index = np.transpose(np.nonzero(MASK)) # nonzero indices of the mask\n",
    "    \n",
    "    ## Initialize time-keeping variables\n",
    "    time_per_iter = []\n",
    "    psnr_per_iter = []\n",
    "    t4 = 0\n",
    "    \n",
    "    # Main PnP SVRG routine\n",
    "    w = np.copy(z)\n",
    "    for i in range(T):\n",
    "        # outer loop\n",
    "        mu = full_grad(w, MASK, meas)   \t# Average gradient\n",
    "        # \tw = np.copy(x) \t\t\t\t\t# reference point\n",
    "        start_iter = time.time()\n",
    "\n",
    "        # inner loop\n",
    "        ind = get_batch(batch_size, H, W, index) \t# Get batch index(indices) in terms of (row, col)\n",
    "\n",
    "        start_grad = time.time()\n",
    "        v = stoch_grad(z, MASK, meas, ind) - stoch_grad(w, MASK, meas, ind) + mu\n",
    "        z = z - eta*v\n",
    "\n",
    "        # Denoising\n",
    "        ztilde = np.copy(z)\n",
    "        z = denoise_nl_means(np.real(ztilde), h=FILTER, fast_mode=True, **patch)\n",
    "\n",
    "        # update reference point with probability 1-p\n",
    "        if np.random.random() > p:\n",
    "            w = np.copy(z)\n",
    "\n",
    "        stop_iter = time.time()\n",
    "        print(str(i) + \" \" + str(peak_signal_noise_ratio(orig, z)))\n",
    "        time_per_iter.append(stop_iter - start_iter)\n",
    "        psnr_per_iter.append(peak_signal_noise_ratio(orig, z))\n",
    "\n",
    "        t4 += 1\n",
    "    return z, time_per_iter, psnr_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_LSVRG = 10 \t\t\t\t# Number of outer loop iterations\n",
    "eta_LSVRG = 1 / L\t\t\t\t# step size for SVRG\n",
    "p_LSVRG = .2\t\t\t\t\t\t# probability of NOT updating reference point\n",
    "batch_size_LSVRG=30000\n",
    "NLM_filter = .015\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6,  # 13x13 search area\n",
    "                multichannel=True)\n",
    "\n",
    "output_LSVRG, time_per_iter_LSVRG, psnr_per_iter_LSVRG = PnP_LSVRG_CSMRI(x_init, mask, y, eta_LSVRG, T_LSVRG, \\\n",
    "                                                                         batch_size_LSVRG, p_LSVRG, \\\n",
    "                                                                         NLM_filter, patch_kw, ORIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display output of PnP-L-SVRG\n",
    "psnr_output_LSVRG = peak_signal_noise_ratio(orig, output_LSVRG)\n",
    "lsvrg_fig = plt.figure()\n",
    "ax = lsvrg_fig.add_subplot(1, 1, 1)\n",
    "lsvrg_plot = plt.imshow(output_LSVRG, cmap='gray', vmin=0, vmax=1)\n",
    "ax.set_title(f\"PnP-L-SVRG, PSNR = {psnr_output_LSVRG:0.2f}\")\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(not yet working, need to learn how to choose parameters)\n",
    "\n",
    "$\\begin{equation}\n",
    "\t\\textbf{PnP-LKatyusha}(\\theta_1, \\theta_2, p \\in (0, 1], T): \\\\\n",
    "    \\text{Initialize } \\boldsymbol{y}_0 = \\boldsymbol{w}_0 = \\boldsymbol{z}_0 \\in \\mathbb{R}^n, \\text{ stepsize } \\eta = \\frac{\\theta_2}{(1 + \\theta_2) \\theta_1} \\text{ and set } \\sigma = \\frac{\\mu}{L}\\\\\n",
    "\t\\text{for } t = 1, 2, . . ., T \\text{ do} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{x}_t = \\theta_1 \\boldsymbol{z}_t + \\theta_2 \\boldsymbol{w}_t + (1 - \\theta_1 - \\theta_2) \\boldsymbol{y}_k \\\\\n",
    "    \\hspace{2ex} \\text{pick } i_t \\in \\{ 1, ..., n \\} \\text{ randomly} \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{g}_t = \\nabla \\ell_i (\\boldsymbol{x}_t) - \\nabla_i \\ell_i (\\boldsymbol{w}_t) + \\nabla \\ell (\\boldsymbol{w}_t) \\\\\n",
    "\t\\hspace{2ex} \\boldsymbol{z}_{t+1} = \\frac{1}{1 + \\eta \\sigma} (\\eta \\sigma \\boldsymbol{x}_t + \\boldsymbol{z}_t - \\frac{\\eta}{L} \\boldsymbol{g}_t) \\\\\n",
    "    \\hspace{2ex} \\boldsymbol{y}_{t+1} = \\boldsymbol{x} + \\theta_1 (\\boldsymbol{z}_{t+1} - \\boldsymbol{z}_t) \\\\\n",
    "\t\\hspace{2ex} \\text{Update} \\hspace{1ex} \\boldsymbol{w}_{t+1} = \\boldsymbol{y}_t\n",
    "\\hspace{2ex} \\text{ w.p. } p \\\\ \\text{end} \\\\\n",
    "    \\textbf{Output } \\boldsymbol{x}_T\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_LKatyusha = 10 \t\t\t\t# Number of outer loop iterations\n",
    "\n",
    "p = .2\t\t\t\t\t\t# probability of NOT updating reference point\n",
    "theta1 = .1\n",
    "theta2 = .1\n",
    "eta_LKatyusha = theta2/((1+theta2)*theta1)\t\t\t\t# step size for SVRG\n",
    "mu = 1\n",
    "L = 1\n",
    "sigma = mu/L\n",
    "\n",
    "batch_size_LKatyusha=30000\n",
    "NLM_filter = .015\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6,  # 13x13 search area\n",
    "                multichannel=True)\n",
    "\n",
    "time_per_iter_LKatyusha = []\n",
    "psnr_per_iter_LKatyusha = []\n",
    "\n",
    "y = np.copy(x_init)\n",
    "w = np.copy(x_init)\n",
    "z = np.copy(x_init)\n",
    "\n",
    "t5 = 0\n",
    "# Main PnP SVRG routine\n",
    "for i in range(T_LKatyusha):\n",
    "    z_old = np.copy(z)\n",
    "    x = theta1*z + theta2*w + (1 - theta1 - theta2)*y\n",
    "    start_iter = time.time()\n",
    "\n",
    "    # inner loop\n",
    "    ind = get_batch(batch_size_LKatyusha, H, W, index) \t# Get batch index(indices) in terms of (row, col)\n",
    "\n",
    "    start_grad = time.time()\n",
    "    g = stoch_grad(x, mask, y, ind) - stoch_grad(w, mask, y, ind) + full_grad(w, mask, y)\n",
    "    z = (1 / (1 + eta_LKatyusha*sigma))*(eta_LKatyusha*sigma*x + z - eta_LKatyusha / L * g)\n",
    "    y = x + theta1*(z - z_old)\n",
    "    \n",
    "    # Denoising\n",
    "    wtilde = np.copy(w)\n",
    "\n",
    "    # denoise\n",
    "    w = denoise_nl_means(np.real(wtilde), h=NLM_filter, fast_mode=True, **patch_kw)\n",
    "    print(str(i) + \" \" + str(peak_signal_noise_ratio(orig, w)))\n",
    "\n",
    "    # update reference point with probability 1-p\n",
    "    if np.random.random() > p:\n",
    "        w = np.copy(y)\n",
    "        \n",
    "    stop_iter = time.time()\n",
    "    time_per_iter_LKatyusha.append(stop_iter - start_iter)\n",
    "    psnr_per_iter_LKatyusha.append(peak_signal_noise_ratio(orig, w))\n",
    "\n",
    "    t5 += 1\n",
    "output_LKatyusha = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display output of PnP-L-Katyusha\n",
    "psnr_output_LKatyusha = peak_signal_noise_ratio(orig, output_LKatyusha)\n",
    "lkatyusha_fig = plt.figure()\n",
    "ax = lkatyusha_fig.add_subplot(1, 1, 1)\n",
    "lkatyusha_plot = plt.imshow(output_LKatyusha, cmap='gray', vmin=0, vmax=1)\n",
    "ax.set_title(f\"PnP-L-Katyusha, PSNR = {psnr_output_LKatyusha:0.2f}\")\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure to display iteration count/ clock time vs PSNR for all algorithms\n",
    "psnr_fig, psnr_ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\n",
    "\n",
    "psnr_ax[0].plot(np.cumsum(time_per_iter_SVRG), psnr_per_iter_SVRG)\n",
    "psnr_ax[0].plot(np.cumsum(time_per_iter_GD), psnr_per_iter_GD)\n",
    "psnr_ax[0].plot(np.cumsum(time_per_iter_SGD), psnr_per_iter_SGD)\n",
    "psnr_ax[0].plot(np.cumsum(time_per_iter_ADMM), psnr_per_iter_ADMM)\n",
    "psnr_ax[0].plot(np.cumsum(time_per_iter_LSVRG), psnr_per_iter_LSVRG)\n",
    "psnr_ax[0].plot(np.cumsum(time_per_iter_LKatyusha), psnr_per_iter_LKatyusha)\n",
    "\n",
    "psnr_ax[1].plot(range(t0), psnr_per_iter_SVRG)\n",
    "psnr_ax[1].plot(range(t1), psnr_per_iter_GD)\n",
    "psnr_ax[1].plot(range(t2), psnr_per_iter_SGD)\n",
    "psnr_ax[1].plot(range(t3), psnr_per_iter_ADMM)\n",
    "psnr_ax[1].plot(range(t4), psnr_per_iter_LSVRG)\n",
    "psnr_ax[1].plot(range(t5), psnr_per_iter_LKatyusha)\n",
    "\n",
    "psnr_ax[0].set(xlabel='time (s)', ylabel='PSNR (dB)')\n",
    "psnr_ax[0].legend(('PnP-SVRG', 'PnP-GD', 'PnP-SGD', 'PnP-ADMM', 'PnP-LSVRG', 'PnP-LKatyusha'), loc='lower right')\n",
    "psnr_ax[0].grid()\n",
    "\n",
    "psnr_ax[1].set(xlabel='iteration', ylabel='PSNR (dB)')\n",
    "psnr_ax[1].legend(('PnP-SVRG','PnP-GD', 'PnP-SGD', 'PnP-ADMM', 'PnP-LSVRG', 'PnP-LKatyusha'), loc='lower right')\n",
    "psnr_ax[1].grid()\n",
    "\n",
    "psnr_fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
